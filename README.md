This project implements a Retrieval-Augmented Generation (RAG) system using FastAPI, FAISS, and OpenAI's GPT-3.5-turbo. It allows users to query iPhone sales data and receive context-aware responses generated by GPT-3.5.

Features Data Preprocessing:

Combines multiple columns into a single context (combined_text) for embeddings. Embeddings are generated using OpenAI's text-embedding-ada-002 model. Indexing:

Uses FAISS for efficient vector-based similarity search. Stores the embeddings in a FAISS index for fast retrieval. Query Interface:

Exposes a REST API using FastAPI for querying the data. Searches the FAISS index for the most relevant data entries. Combines retrieved data as context and queries GPT-3.5 to generate responses. Error Handling:

Implements retry mechanisms for embedding generation. Handles rate limits and invalid requests gracefully. Technologies Used Programming Languages: Python Libraries: FastAPI, Pandas, NumPy, FAISS, OpenAI Python SDK Database: CSV-based storage for embeddings and FAISS index Generative AI: OpenAI GPT-3.5-turbo Environment: Local deployment with FastAPI and Uvicorn Installation and Setup Prerequisites Python 3.8 or above OpenAI API key (store in a file or variable) Steps Clone the repository:

git clone cd Install dependencies:

pip install -r requirements.txt Set up OpenAI API Key:

Create a file named openaiapikeyPv.py with the following content:

def provideApiKey(): return "your_openai_api_key_here" Prepare the Dataset:

Place your CSV file (e.g., iphone.csv) in the dataset directory. Generate Embeddings and Index:

Run the script to generate embeddings and FAISS index:

python create_embeddings_and_index.py Run the API:

Start the FastAPI server:

python query_api.py Test the API:

Use a REST client like Postman or cURL to send a POST request to:

http://127.0.0.1:8000/query/ Example payload: json Copy code { "question": "What are the latest reviews for iPhone 14?", "top_k": 5 } API Endpoints POST /query/ Description: Accepts a user query, retrieves relevant entries using FAISS, and generates a response with GPT-3.5.

Request:

{ "question": "Your question here", "top_k": 3 } Response:

{ "question": "Your question here", "context_used": "Context retrieved from the dataset", "gpt_response": "Response generated by GPT-3.5-turbo" } Skills Gained Generative AI: RAG architecture, GPT-3.5-turbo integration. Vector Search: FAISS for embedding-based similarity search. Backend Development: FastAPI for REST APIs, error handling, and deployment. Data Processing: Pandas, NumPy for dataset manipulation. AI Integration: OpenAI embeddings for knowledge representation. System Design: Architecting a scalable query system. Future Improvements Add authentication for API endpoints. Support for real-time data updates. Deploy on cloud platforms like AWS or GCP. Build a user-friendly frontend for non-technical users.

Author Developed by Pranav
